{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T15:36:09.565741Z",
     "start_time": "2023-12-29T15:36:09.248921Z"
    }
   },
   "id": "cb1e13ef288d3e7a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build an unique dataset based on the median of each feature\n",
    "1- Aggregate each data sensors hourly by applying a mean\n",
    "2- Create an unique dataset by applying a median of each sensor in each hour"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7b993f8a177fd37"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define constants and hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19d82b7487cdf754"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "START_DATE_BOARD    = '2022-11-03'\n",
    "END_DATE_BOARD      = '2023-06-15'\n",
    "PM25_DIRECTORY      = '../resources/dataset/'\n",
    "PM2_MAP = {\n",
    "    \"board20\": [\"s250.csv\", \"s252.csv\", \"s256.csv\", \"s258.csv\"],\n",
    "    \"board20_temp\": [\"s258.csv\"],\n",
    "    \"board20_pres\": [\"s260.csv\"],\n",
    "    \"board20_rh\": [\"s259.csv\"],\n",
    "    \"board21\": [\"s263.csv\", \"s265.csv\", \"s267.csv\", \"s269.csv\"],\n",
    "    \"board21_temp\": [\"s271.csv\"],\n",
    "    \"board21_pres\": [\"s273.csv\"],\n",
    "    \"board21_rh\": [\"s272.csv\"],\n",
    "    \"board22\": [\"s276.csv\", \"s278.csv\", \"s280.csv\", \"s282.csv\"],\n",
    "    \"board22_temp\": [\"s284.csv\"],\n",
    "    \"board22_pres\": [\"s286.csv\"],\n",
    "    \"board22_rh\": [\"s285.csv\"],\n",
    "    \"board25\": [\"s315.csv\", \"s317.csv\", \"s319.csv\", \"s321.csv\"],\n",
    "    \"board25_temp\": [\"s323.csv\"],\n",
    "    \"board25_pres\": [\"s325.csv\"],\n",
    "    \"board25_rh\": [\"s324.csv\"],\n",
    "    \"board29\": [\"s367.csv\", \"s369.csv\", \"s371.csv\", \"s373.csv\"],\n",
    "    \"board29_temp\": [\"s375.csv\"],\n",
    "    \"board29_pres\": [\"s377.csv\"],\n",
    "    \"board29_rh\": [\"s376.csv\"],\n",
    "    \"board31\": [\"s393.csv\", \"s395.csv\", \"s397.csv\", \"s399.csv\"],\n",
    "    \"board31_temp\": [\"s401.csv\"],\n",
    "    \"board31_pres\": [\"s403.csv\"],\n",
    "    \"board31_rh\": [\"s402.csv\"],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T15:36:11.300642Z",
     "start_time": "2023-12-29T15:36:11.297525Z"
    }
   },
   "id": "b2f535862ae371a9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transform each CSV into Pandas dataframe"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aedb8d2aeffdc91e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing folders: 100%|██████████| 34/34 [04:04<00:00,  7.20s/it]\n"
     ]
    }
   ],
   "source": [
    "def prepare_pm25_dataframe(file_name: str) -> pd.DataFrame:\n",
    "    df_pm25             = pd.read_csv(file_name) # mu_g/m^3\n",
    "    df_pm25.timestamp   = pd.to_datetime(df_pm25.timestamp)\n",
    "    df_pm25.drop_duplicates(inplace=True)\n",
    "    df_pm25.sort_values(by='timestamp', inplace=True)\n",
    "    df_pm25 = df_pm25.loc[(df_pm25['timestamp'] >= START_DATE_BOARD) & (df_pm25['timestamp'] <= END_DATE_BOARD)]\n",
    "    df_pm25 = df_pm25.groupby(pd.Grouper(key='timestamp', freq='min')).mean().reset_index()\n",
    "    df_pm25.dropna(inplace=True)\n",
    "    return df_pm25\n",
    "\n",
    "def prepare_generic_dataframe(file_name: str) -> pd.DataFrame:\n",
    "    df             = pd.read_csv(file_name)\n",
    "    df.timestamp   = pd.to_datetime(df.timestamp)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.sort_values(by='timestamp', inplace=True)\n",
    "    df = df.loc[(df['timestamp'] >= START_DATE_BOARD) & (df['timestamp'] <= END_DATE_BOARD)]\n",
    "    df = df.groupby(pd.Grouper(key='timestamp', freq='min')).mean().reset_index()\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "dataframes_pm25 = []\n",
    "dataframes_temp = []\n",
    "dataframes_pres = []\n",
    "dataframes_rh = []\n",
    "for folder_name in tqdm(os.listdir(PM25_DIRECTORY), desc='Analyzing folders'):\n",
    "    folder = os.path.join(PM25_DIRECTORY, folder_name)\n",
    "    if os.path.isdir(folder) and len(folder.split('/')) > 3 and folder.split('/')[3] in PM2_MAP:\n",
    "        files = PM2_MAP[folder.split('/')[3]]\n",
    "        for file_name in files:\n",
    "            file = os.path.join(folder, file_name)\n",
    "            if os.path.isfile(file) and file.endswith(\".csv\"):\n",
    "                df = prepare_generic_dataframe(file)\n",
    "                if folder_name.endswith(\"_temp\"):\n",
    "                    dataframes_temp.append(df)\n",
    "                elif folder_name.endswith(\"_pres\"):\n",
    "                    dataframes_pres.append(df)\n",
    "                elif folder_name.endswith(\"_rh\"):\n",
    "                    dataframes_rh.append(df)\n",
    "                else:\n",
    "                    dataframes_pm25.append(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T15:19:56.524864Z",
     "start_time": "2023-12-29T15:15:51.573635Z"
    }
   },
   "id": "4b0870e543c229c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get an unique dataframe by applying the median in each point"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd9d1d5eb9463338"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building unique dataset: 100%|██████████| 322561/322561 [4:17:25<00:00, 20.88it/s]  \n"
     ]
    }
   ],
   "source": [
    "df_final                = pd.DataFrame(columns=['timestamp', 'pm25', 'temp', 'pres', 'rh'])\n",
    "df_final['timestamp']   = pd.date_range(start=START_DATE_BOARD, end=END_DATE_BOARD, freq='min')\n",
    "pm25_series             = []\n",
    "temp_series             = []\n",
    "pres_series             = []\n",
    "rh_series               = []\n",
    "\n",
    "for pit in tqdm(df_final['timestamp'], desc='Building unique dataset'):\n",
    "    # PM2.5\n",
    "    pm25_values = []\n",
    "    for df in dataframes_pm25:\n",
    "        value = df[df.timestamp == pit]['data'].values\n",
    "        if len(value) > 0:\n",
    "            pm25_values.append(value[0])\n",
    "        #else:\n",
    "        #    pm25_values.append(0)\n",
    "    pm25_series.append(np.median(pm25_values) if len(pm25_values) > 0 else None)\n",
    "    # Temperature\n",
    "    temp_values = []\n",
    "    for df in dataframes_temp:\n",
    "        value = df[df.timestamp == pit]['data'].values\n",
    "        if len(value) > 0:\n",
    "            temp_values.append(value[0])\n",
    "    temp_series.append(np.median(temp_values) if len(temp_values) > 0 else None)\n",
    "    # Pressure\n",
    "    pres_values = []\n",
    "    for df in dataframes_pres:\n",
    "        value = df[df.timestamp == pit]['data'].values\n",
    "        if len(value) > 0:\n",
    "            pres_values.append(value[0])\n",
    "    pres_series.append(np.median(pres_values) if len(pres_values) > 0 else None)\n",
    "    # Humidity\n",
    "    rh_values = []\n",
    "    for df in dataframes_rh:\n",
    "        value = df[df.timestamp == pit]['data'].values\n",
    "        if len(value) > 0:\n",
    "            rh_values.append(value[0])\n",
    "    rh_series.append(np.median(rh_values) if len(rh_values) > 0 else None)\n",
    "\n",
    "df_final['pm25']        = pd.Series(pm25_series)\n",
    "df_final['temp']        = pd.Series(temp_series)\n",
    "df_final['pres']        = pd.Series(pres_series)\n",
    "df_final['rh']          = pd.Series(rh_series)\n",
    "df_final.dropna(inplace=True)\n",
    "df_final.to_csv('../resources/dataset/unique_timeseries_by_median_minutes_all_attributes.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:48:51.610506Z",
     "start_time": "2023-12-17T14:31:25.292506Z"
    }
   },
   "id": "bfad005782d8dc54"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make the same but hourly"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3023a6f01767275a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing folders: 100%|██████████| 30/30 [03:44<00:00,  7.48s/it]\n"
     ]
    }
   ],
   "source": [
    "def prepare_generic_dataframe(file_name: str) -> pd.DataFrame:\n",
    "    df             = pd.read_csv(file_name)\n",
    "    df.timestamp   = pd.to_datetime(df.timestamp)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.sort_values(by='timestamp', inplace=True)\n",
    "    df = df.loc[(df['timestamp'] >= START_DATE_BOARD) & (df['timestamp'] <= END_DATE_BOARD)]\n",
    "    df = df.groupby(pd.Grouper(key='timestamp', freq='H')).mean().reset_index()\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "dataframes_pm25 = []\n",
    "dataframes_temp = []\n",
    "dataframes_pres = []\n",
    "dataframes_rh = []\n",
    "for folder_name in tqdm(os.listdir(PM25_DIRECTORY), desc='Analyzing folders'):\n",
    "    folder = os.path.join(PM25_DIRECTORY, folder_name)\n",
    "    if os.path.isdir(folder) and len(folder.split('/')) > 3 and folder.split('/')[3] in PM2_MAP:\n",
    "        files = PM2_MAP[folder.split('/')[3]]\n",
    "        for file_name in files:\n",
    "            file = os.path.join(folder, file_name)\n",
    "            if os.path.isfile(file) and file.endswith(\".csv\"):\n",
    "                df = prepare_generic_dataframe(file)\n",
    "                if folder_name.endswith(\"_temp\"):\n",
    "                    dataframes_temp.append(df)\n",
    "                elif folder_name.endswith(\"_pres\"):\n",
    "                    dataframes_pres.append(df)\n",
    "                elif folder_name.endswith(\"_rh\"):\n",
    "                    dataframes_rh.append(df)\n",
    "                else:\n",
    "                    dataframes_pm25.append(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T15:40:02.341326Z",
     "start_time": "2023-12-29T15:36:17.789171Z"
    }
   },
   "id": "727d7740daf49aff",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building unique dataset: 100%|██████████| 5377/5377 [00:26<00:00, 206.14it/s]\n"
     ]
    }
   ],
   "source": [
    "df_final                = pd.DataFrame(columns=['timestamp', 'pm25', 'temp', 'pres', 'rh'])\n",
    "df_final['timestamp']   = pd.date_range(start=START_DATE_BOARD, end=END_DATE_BOARD, freq='H')\n",
    "pm25_series             = []\n",
    "temp_series             = []\n",
    "pres_series             = []\n",
    "rh_series               = []\n",
    "\n",
    "for pit in tqdm(df_final['timestamp'], desc='Building unique dataset'):\n",
    "    # PM2.5\n",
    "    pm25_values = []\n",
    "    for df in dataframes_pm25:\n",
    "        value = df[df.timestamp == pit]['data'].values\n",
    "        if len(value) > 0:\n",
    "            pm25_values.append(value[0])\n",
    "        #else:\n",
    "        #    pm25_values.append(0)\n",
    "    pm25_series.append(np.median(pm25_values) if len(pm25_values) > 0 else None)\n",
    "    # Temperature\n",
    "    temp_values = []\n",
    "    for df in dataframes_temp:\n",
    "        value = df[df.timestamp == pit]['data'].values\n",
    "        if len(value) > 0:\n",
    "            temp_values.append(value[0])\n",
    "    temp_series.append(np.median(temp_values) if len(temp_values) > 0 else None)\n",
    "    # Pressure\n",
    "    pres_values = []\n",
    "    for df in dataframes_pres:\n",
    "        value = df[df.timestamp == pit]['data'].values\n",
    "        if len(value) > 0:\n",
    "            pres_values.append(value[0])\n",
    "    pres_series.append(np.median(pres_values) if len(pres_values) > 0 else None)\n",
    "    # Humidity\n",
    "    rh_values = []\n",
    "    for df in dataframes_rh:\n",
    "        value = df[df.timestamp == pit]['data'].values\n",
    "        if len(value) > 0:\n",
    "            rh_values.append(value[0])\n",
    "    rh_series.append(np.median(rh_values) if len(rh_values) > 0 else None)\n",
    "\n",
    "df_final['pm25']        = pd.Series(pm25_series)\n",
    "df_final['temp']        = pd.Series(temp_series)\n",
    "df_final['pres']        = pd.Series(pres_series)\n",
    "df_final['rh']          = pd.Series(rh_series)\n",
    "df_final.dropna(inplace=True)\n",
    "df_final.to_csv('../resources/dataset/unique_timeseries_by_median_hours_all_attributes.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T15:40:28.465439Z",
     "start_time": "2023-12-29T15:40:02.348026Z"
    }
   },
   "id": "825e9b5264fd0bc3",
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
