{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T13:53:02.738366Z",
     "start_time": "2023-12-17T13:53:02.733271Z"
    }
   },
   "id": "cb1e13ef288d3e7a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build an unique dataset based on the median of each feature\n",
    "1- Aggregate each data sensors hourly by applying a mean\n",
    "2- Create an unique dataset by applying a median of each sensor in each hour"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7b993f8a177fd37"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define constants and hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19d82b7487cdf754"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "START_DATE_BOARD    = '2022-11-03'\n",
    "END_DATE_BOARD      = '2023-06-15'\n",
    "PM25_DIRECTORY      = '../resources/dataset/'\n",
    "PM2_MAP = {\n",
    "    \"board20\": [\"s250.csv\", \"s252.csv\", \"s256.csv\", \"s258.csv\"],\n",
    "    \"board20_temp\": [\"s258.csv\"],\n",
    "    \"board20_pres\": [\"s260.csv\"],\n",
    "    \"board20_rh\": [\"s259.csv\"],\n",
    "    \"board21\": [\"s263.csv\", \"s265.csv\", \"s267.csv\", \"s269.csv\"],\n",
    "    \"board22\": [\"s276.csv\", \"s278.csv\", \"s280.csv\", \"s282.csv\"],\n",
    "    \"board25\": [\"s315.csv\", \"s317.csv\", \"s319.csv\", \"s321.csv\"],\n",
    "    \"board29\": [\"s367.csv\", \"s369.csv\", \"s371.csv\", \"s373.csv\"],\n",
    "    \"board31\": [\"s393.csv\", \"s395.csv\", \"s397.csv\", \"s399.csv\"]\n",
    "}\n",
    "\n",
    "# Define the hyperparameter\n",
    "TRAIN_SIZE      = 0.7\n",
    "RANDOM_STATE    = 42\n",
    "INPUT_SIZE      = 60\n",
    "HIDDEN_SIZE     = 128\n",
    "OUTPUT_SIZE     = 1\n",
    "LEARNING_RATE   = 0.0001\n",
    "NUM_EPOCHS      = 200\n",
    "BATCH_SIZE      = 20"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T13:53:40.957473Z",
     "start_time": "2023-12-17T13:53:40.953680Z"
    }
   },
   "id": "b2f535862ae371a9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transform each CSV into Pandas dataframe"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aedb8d2aeffdc91e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing folders:   7%|â–‹         | 2/28 [00:29<06:19, 14.59s/it]"
     ]
    }
   ],
   "source": [
    "def prepare_pm25_dataframe(file_name: str) -> pd.DataFrame:\n",
    "    df_pm25             = pd.read_csv(file_name) # mu_g/m^3\n",
    "    df_pm25.timestamp   = pd.to_datetime(df_pm25.timestamp)\n",
    "    df_pm25.drop_duplicates(inplace=True)\n",
    "    df_pm25.sort_values(by='timestamp', inplace=True)\n",
    "    df_pm25 = df_pm25.loc[(df_pm25['timestamp'] >= START_DATE_BOARD) & (df_pm25['timestamp'] <= END_DATE_BOARD)]\n",
    "    df_pm25 = df_pm25.groupby(pd.Grouper(key='timestamp', freq='min')).mean().reset_index()\n",
    "    df_pm25.dropna(inplace=True)\n",
    "    return df_pm25\n",
    "\n",
    "def prepare_generic_dataframe(file_name: str) -> pd.DataFrame:\n",
    "    df             = pd.read_csv(file_name)\n",
    "    df.timestamp   = pd.to_datetime(df.timestamp)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.sort_values(by='timestamp', inplace=True)\n",
    "    df = df.loc[(df['timestamp'] >= START_DATE_BOARD) & (df['timestamp'] <= END_DATE_BOARD)]\n",
    "    df = df.groupby(pd.Grouper(key='timestamp', freq='min')).mean().reset_index()\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "dataframes_pm25 = []\n",
    "dataframes_temp = []\n",
    "dataframes_pres = []\n",
    "dataframes_rh = []\n",
    "for folder_name in tqdm(os.listdir(PM25_DIRECTORY), desc='Analyzing folders'):\n",
    "    folder = os.path.join(PM25_DIRECTORY, folder_name)\n",
    "    if os.path.isdir(folder) and len(folder.split('/')) > 3 and folder.split('/')[3] in PM2_MAP:\n",
    "        files = PM2_MAP[folder.split('/')[3]]\n",
    "        for file_name in files:\n",
    "            file = os.path.join(folder, file_name)\n",
    "            if os.path.isfile(file) and file.endswith(\".csv\"):\n",
    "                df = prepare_generic_dataframe(file)\n",
    "                if folder_name.endswith(\"_temp\"):\n",
    "                    dataframes_temp.append(df)\n",
    "                elif folder_name.endswith(\"_pres\"):\n",
    "                    dataframes_pres.append(df)\n",
    "                elif folder_name.endswith(\"_rh\"):\n",
    "                    dataframes_rh.append(df)\n",
    "                else:\n",
    "                    dataframes_pm25.append(df)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-17T13:54:40.362795Z"
    }
   },
   "id": "4b0870e543c229c5"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b9d89c3cc12ecc29"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get an unique dataframe by applying the median in each point"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd9d1d5eb9463338"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_final                = pd.DataFrame(columns=['timestamp', 'data'])\n",
    "df_final['timestamp']   = pd.date_range(start=START_DATE_BOARD, end=END_DATE_BOARD, freq='min')\n",
    "pm25_series             = []\n",
    "temp_series             = []\n",
    "pres_series             = []\n",
    "rh_series               = []\n",
    "\n",
    "for pit in tqdm(df_final['timestamp'], desc='Building unique dataset'):\n",
    "    # PM2.5\n",
    "    pm25_values = []\n",
    "    for df in dataframes_pm25:\n",
    "        value = df[df.timestamp == pit]['data'].values\n",
    "        if len(value) > 0:\n",
    "            pm25_values.append(value[0])\n",
    "        #else:\n",
    "        #    pm25_values.append(0)\n",
    "    pm25_series.append(np.median(pm25_values) if len(pm25_values) > 0 else None)\n",
    "    # Temperature\n",
    "    temp_values = []\n",
    "    for df in dataframes_temp:\n",
    "        value = df[df.timestamp == pit]['data'].values\n",
    "        if len(value) > 0:\n",
    "            temp_values.append(value[0])\n",
    "    temp_series.append(np.median(temp_values) if len(temp_values) > 0 else None)\n",
    "    # Pressure\n",
    "    pres_values = []\n",
    "    for df in dataframes_pres:\n",
    "        value = df[df.timestamp == pit]['data'].values\n",
    "        if len(value) > 0:\n",
    "            pres_values.append(value[0])\n",
    "    pres_series.append(np.median(pres_values) if len(pres_values) > 0 else None)\n",
    "    # Humidity\n",
    "    rh_values = []\n",
    "    for df in dataframes_rh:\n",
    "        value = df[df.timestamp == pit]['data'].values\n",
    "        if len(value) > 0:\n",
    "            rh_values.append(value[0])\n",
    "    rh_series.append(np.median(rh_values) if len(rh_values) > 0 else None)\n",
    "\n",
    "df_final['pm25']        = pd.Series(pm25_series)\n",
    "df_final['temp']        = pd.Series(temp_series)\n",
    "df_final['pres']        = pd.Series(pres_series)\n",
    "df_final['rh']          = pd.Series(rh_series)\n",
    "df_final.dropna(inplace=True)\n",
    "df_final.to_csv('../resources/dataset/unique_timeseries_by_median_minutes_all_attributes.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfad005782d8dc54"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
