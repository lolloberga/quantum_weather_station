{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:29.603927Z",
     "start_time": "2024-01-10T21:37:29.603487Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from model.loss_functions.RMSELoss import RMSELoss\n",
    "from utils.dataset_utils import DatasetUtils"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define constants\n",
    "START_DATE_BOARD = '2022-11-03'\n",
    "END_DATE_BOARD = '2023-06-15'\n",
    "RANDOM_STATE = 42"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T21:37:30.984825Z",
     "start_time": "2024-01-10T21:37:30.981076Z"
    }
   },
   "id": "6ec0954650793348",
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Benchmark Loss\n",
    "The goal of this notebook is to compute the same loss of the 3 models (LSTM, ANN, VQR) in the same portion of test set. The result will be the benchmark that each model has to overcome."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9641fbe3b36169f2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LSTM model\n",
    "Best hyperparams:\n",
    "- optimizer: ADAM\n",
    "- criterion: L1\n",
    "- learning rate: 0.001\n",
    "- num epochs: 450\n",
    "- hidden size: 600\n",
    "- T: 3\n",
    "- train size: 70%\n",
    "\n",
    "Final loss on test set: 2.7362"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8f94a3141b1ae30"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ANN model\n",
    "Best hyperparams:\n",
    "- optmizier: SGD\n",
    "- criterion: L1\n",
    "- learning rate: 0.0001\n",
    "- num epochs: 200\n",
    "- hidden size: 60\n",
    "- hidden size layer 2: ?\n",
    "- hidden size layer 3: ?\n",
    "- train size: 70%\n",
    "\n",
    "Final loss on test set: 5.3008"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abb5a601268c4f40"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### VQR Non linear model\n",
    "Best hyperparams:\n",
    "- optmizier: \n",
    "- criterion: \n",
    "- learning rate: \n",
    "- num epochs: \n",
    "- num layers: \n",
    "- train size: 70%\n",
    "\n",
    "Final loss on test set:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b853da927e396641"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define best hyperparams for LSTM\n",
    "TRAIN_SIZE      = 0.75\n",
    "CRITERION_L1    = nn.L1Loss()\n",
    "CRITERION_RMSE  = RMSELoss()\n",
    "CRITERION_MSE  = nn.MSELoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T22:16:10.404405Z",
     "start_time": "2024-01-10T22:16:10.403937Z"
    }
   },
   "id": "6e27eb729508d368",
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Build the same dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb0308d45fb8a48e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_sensors = pd.read_csv('../resources/dataset/unique_timeseries_by_median_hours.csv')\n",
    "df_sensors.timestamp = pd.to_datetime(df_sensors.timestamp)\n",
    "df_sensors.timestamp += pd.Timedelta(hours=1)\n",
    "df_arpa = DatasetUtils.build_arpa_dataset('../resources/dataset/arpa/Dati PM10_PM2.5_2020-2022.csv', '../resources/dataset/arpa/Torino-Rubino_Polveri-sottili_2023-01-01_2023-06-30.csv', START_DATE_BOARD, END_DATE_BOARD)\n",
    "\n",
    "df = df_sensors.merge(df_arpa, left_on=['timestamp'], right_on=['timestamp'])\n",
    "df.rename(columns={\"data\": \"x\", \"pm25\": \"y\"}, inplace=True)\n",
    "# Slide ARPA data 1 hour plus\n",
    "df['y'] = DatasetUtils.slide_plus_1hours(df['y'], df['x'][0])\n",
    "X = df.x.values\n",
    "y = df.y.values\n",
    "_, X_test, _, y_test = train_test_split(X, y, train_size=TRAIN_SIZE,\n",
    "                                                    shuffle=False,\n",
    "                                                    random_state=RANDOM_STATE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T22:16:12.260579Z",
     "start_time": "2024-01-10T22:16:12.168199Z"
    }
   },
   "id": "4182c1e566a93da5",
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Compute the loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96f40e5183b9f78"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "4.701448917388916"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CRITERION_L1(torch.from_numpy(X_test.astype(np.float32)), torch.from_numpy(y_test.astype(np.float32))).item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T22:16:14.952134Z",
     "start_time": "2024-01-10T22:16:14.940009Z"
    }
   },
   "id": "6a4eef28b157b43a",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "5.823546409606934"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CRITERION_RMSE(torch.from_numpy(X_test.astype(np.float32)), torch.from_numpy(y_test.astype(np.float32))).item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T22:16:19.728108Z",
     "start_time": "2024-01-10T22:16:19.724555Z"
    }
   },
   "id": "3a72eae96560a88f",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "33.913692474365234"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CRITERION_MSE(torch.from_numpy(X_test.astype(np.float32)), torch.from_numpy(y_test.astype(np.float32))).item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T22:16:21.277980Z",
     "start_time": "2024-01-10T22:16:21.274302Z"
    }
   },
   "id": "56f63d18e864f0b3",
   "execution_count": 62
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
